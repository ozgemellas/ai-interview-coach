# AI Interview Coach (Ã–zgeLLM Final)

Bu proje, en son teknoloji **Yapay Zeka** ve **Web Teknolojilerini** birleÅŸtirerek oluÅŸturulmuÅŸ, tamamen yerel makinenizde Ã§alÄ±ÅŸan (Privacy-First) devrimsel bir **Sanal MÃ¼lakat KoÃ§u** uygulamasÄ±dÄ±r. 

KullanÄ±cÄ±lara gerÃ§ek bir Ä°nsan KaynaklarÄ± uzmanÄ± ile konuÅŸuyormuÅŸ hissi vermek iÃ§in **Llama 3** dil modeli, **Edge-TTS** ses sentezleme teknolojisi ve **React Three Fiber** tabanlÄ± 3D avatar gÃ¶rselleÅŸtirmesi kullanÄ±r.

![Project Banner](https://via.placeholder.com/800x200?text=AI+Interview+Coach+Demo)

## ğŸŒŸ Ã–ne Ã‡Ä±kan Ã–zellikler

*   **ğŸ§  Yerel ve AkÄ±llÄ± Zeka (Local LLM):** Meta'nÄ±n gÃ¼Ã§lÃ¼ **Llama 3 8B Instruct** modelini (`Q4_K_M` quantization ile) kullanarak, internet baÄŸlantÄ±sÄ±na ihtiyaÃ§ duymadan, KVKK uyumlu ve gizli bir mÃ¼lakat deneyimi sunar.
*   **ğŸ—£ï¸ DoÄŸal Ses Deneyimi (TTS):** Microsoft Edge'in `en-US-AriaNeural` (veya TÃ¼rkÃ§e varyasyonlarÄ±) motorunu kullanarak robottan uzak, vurgulamalÄ± ve doÄŸal bir konuÅŸma sesi Ã¼retir.
*   **ğŸ‘¤ 3D Sanal Avatar:** `React Three Fiber` ve `Drei` kÃ¼tÃ¼phaneleri ile gÃ¼Ã§lendirilmiÅŸ, tarayÄ±cÄ± Ã¼zerinde Ã§alÄ±ÅŸan interaktif bir 3D karakter. (KonuÅŸma esnasÄ±nda dudak senkronizasyonu ve jestler - *geliÅŸtirme aÅŸamasÄ±nda*).
*   **âš¡ DÃ¼ÅŸÃ¼k Gecikme (Low Latency):** `FastAPI` ve asenkron (`async/await`) mimari sayesinde anlÄ±k cevaplar.
*   **ğŸ“„ PDF Raporlama:** MÃ¼lakat sonunda performansÄ±nÄ±zÄ± analiz eden Ã§Ä±ktÄ±lar alabilme (`jspdf` entegrasyonu).
*   **ğŸ› ï¸ Kolay Kurulum:** Tek bir script (`tek_tikla_baslat.bat`) ile tÃ¼m servislerin ayaÄŸa kaldÄ±rÄ±lmasÄ±.

## ğŸ—ï¸ Mimari ve Teknolojiler

Proje, modern ve Ã¶lÃ§eklenebilir bir **Microservice** (benzeri) mimari Ã¼zerine kurulmuÅŸtur:

### Backend (Python & AI)
Sunucu tarafÄ±, yapay zeka iÅŸlemlerini yÃ¶netir ve frontend ile API aracÄ±lÄ±ÄŸÄ±yla haberleÅŸir.
*   **Framework:** `FastAPI` (YÃ¼ksek performanslÄ±, asenkron web servisi).
*   **AI Engine:** `llama-cpp-python`. Bu kÃ¼tÃ¼phane, C++ ile yazÄ±lmÄ±ÅŸ `llama.cpp` projesinin Python baÄŸlayÄ±cÄ±sÄ±dÄ±r ve modelin standart donanÄ±mlarda (CPU/GPU) ÅŸaÅŸÄ±rtÄ±cÄ± derecede hÄ±zlÄ± Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar.
    *   *Context Window:* 4096 token (Uzun konuÅŸmalarÄ± hatÄ±rlama kapasitesi).
    *   *Temperature:* 0.7 (YaratÄ±cÄ± ama tutarlÄ± yanÄ±tlar).
*   **Ses Servisi:** `edge-tts` (Online kalitesinde offline ses Ã¼retimi).
*   **Sunucu:** `Uvicorn` (ASGI sunucusu).

### Frontend (User Interface)
KullanÄ±cÄ± deneyiminin aktÄ±ÄŸÄ± modern web arayÃ¼zÃ¼.
*   **Core:** `React 19` + `Vite` (Ultra hÄ±zlÄ± geliÅŸtirme ve build sÃ¼reci).
*   **Dil:** `TypeScript` (Tip gÃ¼venli ve hatasÄ±z kodlama).
*   **Styling:** `TailwindCSS v4` (Modern ve responsive tasarÄ±m sistemi).
*   **3D Graphics:** 
    *   `Three.js`: WebGL motoru.
    *   `@react-three/fiber`: React iÃ§in Three.js renderlayÄ±cÄ±sÄ±.
    *   `@react-three/drei`: HazÄ±r 3D bileÅŸenleri (Kamera, IÅŸÄ±k, Ortam).
*   **Durum YÃ¶netimi:** React Hooks (`useState`, `useEffect`, `useRef`).

## ğŸ“‚ DetaylÄ± Proje YapÄ±sÄ±

```
ozgellmfinal/
â”œâ”€â”€ backend/                  # ARKA UÃ‡ (Logic & AI)
â”‚   â”œâ”€â”€ main.py              # API Gateway (Endpoints: /chat)
â”‚   â”œâ”€â”€ services.py          # LLM ve TTS servislerinin mantÄ±ksal katmanÄ±
â”‚   â”œâ”€â”€ requirements.txt     # Python kÃ¼tÃ¼phane baÄŸÄ±mlÄ±lÄ±klarÄ±
â”‚   â””â”€â”€ __pycache__/         # DerlenmiÅŸ Python dosyalarÄ±
â”œâ”€â”€ frontend/                 # Ã–N YÃœZ (UI & UX)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx  # Ana sohbet ekranÄ± ve mantÄ±ÄŸÄ±
â”‚   â”‚   â”‚   â”œâ”€â”€ Avatar.tsx         # 3D Model dosyasÄ± ve animasyon kontrolÃ¼
â”‚   â”‚   â”‚   â””â”€â”€ Experience.tsx     # 3D sahne ayarlarÄ± (IÅŸÄ±k, Ortam)
â”‚   â”‚   â”œâ”€â”€ App.tsx          # Ana uygulama konteyneri
â”‚   â”‚   â””â”€â”€ index.css        # Tailwind ve global stiller
â”‚   â”œâ”€â”€ vite.config.ts       # Vite yapÄ±landÄ±rmasÄ±
â”‚   â””â”€â”€ package.json         # NPM paketleri ve scriptler
â”œâ”€â”€ ai_interview_coach.ipynb # Model Ar-Ge ve Prompt MÃ¼hendisliÄŸi notlarÄ±
â”œâ”€â”€ LLM_Rapor.pdf            # Akademik/Teknik Proje Raporu
â”œâ”€â”€ tek_tikla_baslat.bat     # Windows iÃ§in Otomatik BaÅŸlatÄ±cÄ±
â””â”€â”€ llama-3-8b-instruct.Q4_K_M.gguf # Ã–NEMLÄ°: BÃ¼yÃ¼k Dil Modeli DosyasÄ±
```

## âš™ï¸ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma Rehberi

### Ã–n Gereksinimler
*   **Ä°ÅŸletim Sistemi:** Windows 10/11 (Linux/Mac de destekler ancak `.bat` dosyasÄ± Windows iÃ§indir).
*   **Python:** SÃ¼rÃ¼m 3.10 veya Ã¼zeri.
*   **Node.js:** SÃ¼rÃ¼m 18 veya Ã¼zeri (Frontend iÃ§in).
*   **RAM:** En az 8GB (16GB Ã¶nerilir).
*   **Model DosyasÄ±:** `llama-3-8b-instruct.Q4_K_M.gguf` dosyasÄ±nÄ±n proje ana dizininde bulunduÄŸundan emin olun.

### AdÄ±m AdÄ±m Kurulum

#### 1. Projeyi KlonlayÄ±n
```bash
git clone https://github.com/kullaniciadi/ozgellmfinal.git
cd ozgellmfinal
```

#### 2. Backend BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± YÃ¼kleyin
```bash
cd backend
# Sanal ortam oluÅŸturmanÄ±z Ã¶nerilir (Opsiyonel)
python -m venv venv
venv\Scripts\activate

pip install -r requirements.txt
cd ..
```
*> Not: CUDA destekli bir NVIDIA ekran kartÄ±nÄ±z varsa, `llama-cpp-python` kÃ¼tÃ¼phanesini GPU desteÄŸiyle kurarak performansÄ± 10x artÄ±rabilirsiniz.*

#### 3. Frontend BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± YÃ¼kleyin
```bash
cd frontend
npm install
cd ..
```

### ğŸš€ UygulamayÄ± BaÅŸlatma

**YÃ¶ntem A: Otomatik (Ã–nerilen)**
Ana dizindeki `tek_tikla_baslat.bat` dosyasÄ±na Ã§ift tÄ±klayÄ±n. Bu script:
1.  Python backend sunucusunu yeni bir pencerede baÅŸlatÄ±r.
2.  Node.js development sunucusunu yeni bir pencerede baÅŸlatÄ±r.
3.  Uygulamaya hazÄ±r olduÄŸunda tarayÄ±cÄ± otomatik aÃ§Ä±lmazsa linkleri gÃ¶sterir.

**YÃ¶ntem B: Manuel**
*Terminal 1 (Backend):*
```bash
cd backend
python main.py
```
*Backend `http://127.0.0.1:8000` adresinde Ã§alÄ±ÅŸacaktÄ±r.*

*Terminal 2 (Frontend):*
```bash
cd frontend
npm run dev
```
*Frontend `http://localhost:5173` (veya terminalde belirtilen port) adresinde Ã§alÄ±ÅŸacaktÄ±r.*

## ï¿½ Sorun Giderme (Troubleshooting)

*   **"Model file not found" hatasÄ±:** `llama-3-8b-instruct.Q4_K_M.gguf` dosyasÄ±nÄ±n tam olarak `ozgellmfinal` klasÃ¶rÃ¼nÃ¼n iÃ§inde (backend veya frontend klasÃ¶rÃ¼nÃ¼n iÃ§inde DEÄÄ°L) olduÄŸunu kontrol edin.
*   **Ses gelmiyor:** TarayÄ±cÄ±nÄ±zÄ±n "Otomatik Oynatma" (Autoplay) izinlerini kontrol edin. Genellikle sayfaya bir kez tÄ±kladÄ±ktan sonra sesler aktif olur.
*   **C++ Build Tools HatasÄ±:** Python paketlerini yÃ¼klerken hata alÄ±rsanÄ±z, bilgisayarÄ±nÄ±zda "Visual Studio C++ Build Tools"un yÃ¼klÃ¼ olduÄŸundan emin olun (Ã¶zellikle `llama-cpp-python` iÃ§in gereklidir).

## ï¿½ Lisans ve Ä°letiÅŸim

Bu proje aÃ§Ä±k kaynaklÄ±dÄ±r ve eÄŸitim amaÃ§lÄ± geliÅŸtirilmiÅŸtir. 
*   **GeliÅŸtirici:** [AdÄ±nÄ±z/Ekibiniz]
*   **Model LisansÄ±:** Meta Llama 3 Community License.

---
*Powered by Llama 3 & React Three Fiber*
